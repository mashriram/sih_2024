{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"../../sih_2024_data_source/statewise_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "\n",
    "def get_scores(y_test, y_pred):\n",
    "    r2_ = r2_score(y_test, y_pred)\n",
    "    rmse_ = root_mean_squared_error(y_test, y_pred)\n",
    "    mae_ = mean_absolute_error(y_test, y_pred)\n",
    "    return {\"r2\": r2_, \"mae\": mae_, \"rmse\": rmse_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, NHITS, DeepAR, TFT, LSTM, RNN, GRU\n",
    "from neuralforecast.losses.pytorch import DistributionLoss, MAE, MSE, MAPE, SMAPE\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import (\n",
    "    NHiTSModel,)\n",
    "\n",
    "def create_darts_models(input_chunk_length=120, output_chunk_length=30, n_epochs=100):\n",
    "    \"\"\"\n",
    "    Create a collection of Darts models with correct parameters\n",
    "    \"\"\"\n",
    "    # Common parameters for neural networks\n",
    "    nn_params = {\n",
    "        \"input_chunk_length\": input_chunk_length,\n",
    "        \"output_chunk_length\": output_chunk_length,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"batch_size\": 32,\n",
    "        \"force_reset\": True,\n",
    "    }\n",
    "\n",
    "    models = {\n",
    "       \n",
    "        \"nhits\": NHiTSModel(\n",
    "            **nn_params,\n",
    "            num_stacks=3,\n",
    "            num_blocks=1,\n",
    "            num_layers=2,\n",
    "            layer_widths=512,\n",
    "            pooling_kernel_sizes=None,\n",
    "            n_freq_downsample=None,\n",
    "            dropout=0.1,\n",
    "            activation=\"ReLU\",\n",
    "            MaxPool1d=True,\n",
    "        ),\n",
    "               \n",
    "    }\n",
    "\n",
    "    return models\n",
    "\n",
    "def train_and_forecast(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Train models and generate forecasts using either Nixtla or Darts\n",
    "    \"\"\"\n",
    "\n",
    "    # Darts workflow\n",
    "    # Convert pandas DataFrame to Darts TimeSeries\n",
    "    series = TimeSeries.from_dataframe(df_train, \"ds\", \"y\",fill_missing_dates=True, freq=None)\n",
    "\n",
    "    # Create and train models\n",
    "    models = create_darts_models()\n",
    "    forecasts = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name} model...\")\n",
    "        model.fit(series)\n",
    "        forecast = model.predict(len(df_test))\n",
    "        \n",
    "        forecasts[name] = {\"data\":forecast,\"model\":model}\n",
    "\n",
    "    return forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_interpolated_ranges(dataframe,date_col,value_col):\n",
    "    dataframe[date_col] = pd.to_datetime(dataframe[date_col])\n",
    "    date_range = pd.date_range(start=dataframe[date_col].min(), end=dataframe[date_col].max())\n",
    "    full_df = pd.DataFrame({date_col: date_range})\n",
    "    merged_df = pd.merge(full_df, dataframe, on=date_col, how='left')\n",
    "    merged_df[value_col] = merged_df[value_col].interpolate()\n",
    "    merged_df[value_col] = merged_df[value_col].fillna(method='bfill').fillna(method='ffill')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import mod\n",
    "import os\n",
    "from re import I\n",
    "\n",
    "ers = {}\n",
    "for commodity in os.listdir(DATA_SOURCE):\n",
    "    print(commodity)\n",
    "    ers[commodity] = {}\n",
    "    path = DATA_SOURCE + commodity\n",
    "    for state_csv in os.listdir(path):\n",
    "        sub_path = path + '/'+ state_csv\n",
    "        state = state_csv.partition(\"_\")[0]\n",
    "        df = pd.read_csv(sub_path)\n",
    "        # df['datetime'] = pd.to_datetime(df['date'])\n",
    "        df.drop(columns=[\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "        df.sort_values(by=\"datetime\", ascending=True, inplace=True)\n",
    "        # print(df.head())\n",
    "        TRAIN_LEN = int(0.8 * len(df))\n",
    "        df_train, df_test = (df[:TRAIN_LEN],df[TRAIN_LEN:])\n",
    "        if(df_train.shape[0]<151  or df_test.shape[0]<15):\n",
    "            continue\n",
    "        df_train.set_index('datetime', inplace=True)\n",
    "        df_train.sort_index(inplace=True)\n",
    "        df_test.set_index('datetime', inplace=True)\n",
    "        df_test.sort_index(inplace=True)\n",
    "        df_train_dt = df_train.groupby(\"datetime\").agg( {\"modal_rs_quintal\": \"mean\"})\n",
    "        df_test_dt = df_test.groupby(\"datetime\").agg( {\"modal_rs_quintal\": \"mean\"})\n",
    "        df_train_dt.reset_index(inplace=True)\n",
    "        df_train_dt.rename(\n",
    "            columns={\"datetime\": \"ds\", \"modal_rs_quintal\": \"y\"}, inplace=True\n",
    "        )\n",
    "        df_test_dt.reset_index(inplace=True)\n",
    "        df_test_dt.rename(\n",
    "            columns={\"datetime\": \"ds\", \"modal_rs_quintal\": \"y\"}, inplace=True\n",
    "        )\n",
    "        ######\n",
    "        print(df_test_dt.shape,df_train_dt.shape)\n",
    "        print(df_train_dt['ds'].unique())\n",
    "        df_train_dt = create_interpolated_ranges(df_train_dt,\"ds\",\"y\")\n",
    "        df_test_dt = create_interpolated_ranges(df_test_dt,\"ds\",\"y\")\n",
    "        print(df_train_dt.head(20))\n",
    "        if(df_train_dt.shape[0]<151  or df_test_dt.shape[0]<15):\n",
    "            continue\n",
    "        nhits_forecast = train_and_forecast(df_train=df_train_dt,df_test=df_test_dt)\n",
    "        print(nhits_forecast)\n",
    "        for name,data_model in nhits_forecast.items():\n",
    "            os.makedirs(f'./model_results/{commodity}/{state}/',exist_ok=True)\n",
    "            nhits_forecast[name][\"model\"].save(f'./model_results/{commodity}/{state}/nhits.pkt')\n",
    "            nhits_forecast[name] = pd.DataFrame(nhits_forecast[name]['data'].values())[0]\n",
    "        result = pd.DataFrame(nhits_forecast)\n",
    "        result_y = df_test_dt['y']\n",
    "        results = pd.concat([result,result_y],axis= 1)\n",
    "        for column in results.columns:\n",
    "            scores[column] = get_scores(results[\"y\"], results[column])\n",
    "        \n",
    "\n",
    "        results.to_csv(f'./model_results/{commodity}/results.csv')\n",
    "        error_results = pd.DataFrame(scores)\n",
    "        error_results.to_csv(f\"./model_results/{commodity}/errors.csv\")\n",
    "        ers[state] = {'results':results,'error_results':error_results}\n",
    "        px.line(\n",
    "        results,\n",
    "        x=results.index,\n",
    "        y=[\n",
    "            \"y\",\n",
    "            \"nhits\",\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
