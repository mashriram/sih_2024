{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import boxcox_normmax\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast.losses.pytorch import MAE, DistributionLoss\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_name</th>\n",
       "      <th>market_name</th>\n",
       "      <th>commodity</th>\n",
       "      <th>variety</th>\n",
       "      <th>grade</th>\n",
       "      <th>min_rs_quintal</th>\n",
       "      <th>max_rs_quintal</th>\n",
       "      <th>modal_rs_quintal</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714742</th>\n",
       "      <td>Bijnor</td>\n",
       "      <td>Bijnaur</td>\n",
       "      <td>Onion</td>\n",
       "      <td>Red</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>01 Jan 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433767</th>\n",
       "      <td>Mau(Maunathbhanjan)</td>\n",
       "      <td>Kopaganj</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>Dara</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>01 Jan 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439485</th>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>Dara</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>01 Jan 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83163</th>\n",
       "      <td>Shahjahanpur</td>\n",
       "      <td>Tilhar</td>\n",
       "      <td>Potato</td>\n",
       "      <td>Potato</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>490.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>01 Jan 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730321</th>\n",
       "      <td>Bulandshahar</td>\n",
       "      <td>Divai</td>\n",
       "      <td>Onion</td>\n",
       "      <td>Red</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>01 Jan 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              district_name market_name commodity variety grade  \\\n",
       "714742               Bijnor     Bijnaur     Onion     Red   FAQ   \n",
       "433767  Mau(Maunathbhanjan)    Kopaganj     Wheat    Dara   FAQ   \n",
       "439485            Gorakhpur   Gorakhpur     Wheat    Dara   FAQ   \n",
       "83163          Shahjahanpur      Tilhar    Potato  Potato   FAQ   \n",
       "730321         Bulandshahar       Divai     Onion     Red   FAQ   \n",
       "\n",
       "        min_rs_quintal  max_rs_quintal  modal_rs_quintal         date  year  \\\n",
       "714742          2950.0          3040.0            3000.0  01 Jan 2018  2018   \n",
       "433767          1525.0          1625.0            1575.0  01 Jan 2018  2018   \n",
       "439485          1560.0          1590.0            1575.0  01 Jan 2018  2018   \n",
       "83163            490.0           510.0             500.0  01 Jan 2018  2018   \n",
       "730321          2800.0          3000.0            2900.0  01 Jan 2018  2018   \n",
       "\n",
       "       month  day_of_month   datetime  \n",
       "714742   Jan             1 2018-01-01  \n",
       "433767   Jan             1 2018-01-01  \n",
       "439485   Jan             1 2018-01-01  \n",
       "83163    Jan             1 2018-01-01  \n",
       "730321   Jan             1 2018-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_up = pd.read_csv(\"../data/5_yr_data/UP5_years.csv\")\n",
    "df_up['datetime'] = pd.to_datetime(df_up['date'])\n",
    "df_up.drop(columns=[\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "df_up.sort_values(by=\"datetime\", ascending=True, inplace=True)\n",
    "df_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LEN = int(0.8 * len(df_up))\n",
    "up_train, up_test = (df_up[:TRAIN_LEN],df_up[TRAIN_LEN:])\n",
    "up_train.set_index('datetime', inplace=True)\n",
    "up_train.sort_index(inplace=True)\n",
    "up_test.set_index('datetime', inplace=True)\n",
    "up_test.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modal_rs_quintal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>2244.840426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>2261.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>2235.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>2258.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>2291.752941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29</th>\n",
       "      <td>2648.738739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-30</th>\n",
       "      <td>2665.293103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>2614.902913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>2653.594340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>2596.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1949 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            modal_rs_quintal\n",
       "datetime                    \n",
       "2018-01-01       2244.840426\n",
       "2018-01-02       2261.681818\n",
       "2018-01-03       2235.193548\n",
       "2018-01-04       2258.073684\n",
       "2018-01-05       2291.752941\n",
       "...                      ...\n",
       "2023-04-29       2648.738739\n",
       "2023-04-30       2665.293103\n",
       "2023-05-01       2614.902913\n",
       "2023-05-02       2653.594340\n",
       "2023-05-03       2596.029412\n",
       "\n",
       "[1949 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "commodity = \"Rice\"\n",
    "df_train_commodity = up_train[up_train['commodity'] == commodity]\n",
    "df_train_commodity_dt = df_train_commodity.groupby(\"datetime\").agg({\"modal_rs_quintal\":\"mean\"})\n",
    "df_train_commodity_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modal_rs_quintal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>2581.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>2681.118421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>2662.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-06</th>\n",
       "      <td>2594.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-07</th>\n",
       "      <td>2559.982456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            modal_rs_quintal\n",
       "datetime                    \n",
       "2023-05-03       2581.857143\n",
       "2023-05-04       2681.118421\n",
       "2023-05-05       2662.755102\n",
       "2023-05-06       2594.227273\n",
       "2023-05-07       2559.982456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_commodity = up_test[up_test['commodity'] == commodity]\n",
    "df_test_commodity_dt = df_test_commodity.groupby(\"datetime\").agg({\"modal_rs_quintal\":\"mean\"})\n",
    "df_test_commodity_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2244.840426</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2261.681818</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2235.193548</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2258.073684</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2291.752941</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds            y unique_id\n",
       "0 2018-01-01  2244.840426      Rice\n",
       "1 2018-01-02  2261.681818      Rice\n",
       "2 2018-01-03  2235.193548      Rice\n",
       "3 2018-01-04  2258.073684      Rice\n",
       "4 2018-01-05  2291.752941      Rice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_commodity_dt.reset_index(inplace=True)\n",
    "df_train_commodity_dt['unique_id'] = commodity\n",
    "df_train_commodity_dt.rename(columns={\"datetime\" : \"ds\", \"modal_rs_quintal\" : \"y\"}, inplace=True)\n",
    "df_train_commodity_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>2581.857143</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>2681.118421</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>2662.755102</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>2594.227273</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>2559.982456</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds            y unique_id\n",
       "0 2023-05-03  2581.857143      Rice\n",
       "1 2023-05-04  2681.118421      Rice\n",
       "2 2023-05-05  2662.755102      Rice\n",
       "3 2023-05-06  2594.227273      Rice\n",
       "4 2023-05-07  2559.982456      Rice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_commodity_dt.reset_index(inplace=True)\n",
    "df_test_commodity_dt['unique_id'] = commodity\n",
    "df_test_commodity_dt.rename(columns={\"datetime\" : \"ds\", \"modal_rs_quintal\" : \"y\"}, inplace=True)\n",
    "df_test_commodity_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1949, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_commodity_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_commodity_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# For Nixtla models\\nnixtla_forecasts = train_and_forecast(df_train_commodity_dt, df_test_commodity_dt, use_nixtla=True)\\n\\n# For Darts models\\ndarts_forecasts = train_and_forecast(df_train_commodity_dt, df_test_commodity_dt, use_nixtla=False)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, NHITS, DeepAR, TFT, LSTM, RNN, GRU\n",
    "from neuralforecast.losses.pytorch import DistributionLoss, MAE, MSE, MAPE, SMAPE\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import (\n",
    "    NBEATSModel,\n",
    "    NHiTSModel,\n",
    "    BlockRNNModel,\n",
    "    TCNModel,\n",
    "    TiDEModel,\n",
    "    TransformerModel,\n",
    "    RandomForest,\n",
    "    LightGBMModel,\n",
    "    XGBModel,\n",
    "    Prophet,\n",
    ")\n",
    "\n",
    "\n",
    "def create_nixtla_models(input_size=120, output_size=368):\n",
    "    \"\"\"\n",
    "    Create a collection of Nixtla models with correct parameters\n",
    "    \"\"\"\n",
    "    # Common parameters\n",
    "    common_params = {\n",
    "        \"input_size\": input_size,\n",
    "        \"h\": output_size,\n",
    "        \"max_steps\": 100,\n",
    "        \"val_check_steps\": 16,\n",
    "        \"early_stop_patience_steps\": 4,\n",
    "    }\n",
    "\n",
    "    # N-BEATS model\n",
    "    nbeats = NBEATS(\n",
    "        **common_params,\n",
    "        loss=DistributionLoss(distribution=\"Normal\", level=[80, 90]),\n",
    "        stack_types=[\"trend\", \"seasonality\"],\n",
    "        num_blocks=[3, 3],\n",
    "        num_layers=[4, 4],\n",
    "        layer_widths=[256, 2048],\n",
    "        expansion_coefficient_lengths=[5, 7],\n",
    "        trend_polynomial_degree=2,\n",
    "    )\n",
    "\n",
    "    # N-HiTS model\n",
    "    nhits = NHITS(\n",
    "        **common_params,\n",
    "        loss=DistributionLoss(distribution=\"Normal\", level=[80, 90]),\n",
    "        num_stacks=3,  # Default is 3\n",
    "        hidden_size=128,  # Units per hidden layer\n",
    "        n_freq_downsample=[168, 24, 1],  # Pooling factor per stack\n",
    "        pooling_kernel_sizes=[168, 24, 1],\n",
    "        interpretation=False,\n",
    "        activation=\"ReLU\",\n",
    "    )\n",
    "\n",
    "    # DeepAR model\n",
    "    deepar = DeepAR(\n",
    "        **common_params,\n",
    "        loss=DistributionLoss(distribution=\"StudentT\", level=[80, 90]),\n",
    "        hidden_size=128,\n",
    "        rnn_layers=2,\n",
    "        dropout=0.1,\n",
    "        cell_type=\"LSTM\",\n",
    "    )\n",
    "\n",
    "    # Temporal Fusion Transformer\n",
    "    tft = TFT(\n",
    "        **common_params,\n",
    "        loss=DistributionLoss(distribution=\"Normal\", level=[80, 90]),\n",
    "        hidden_size=128,  # Hidden state size\n",
    "        lstm_hidden_size=64,  # Size of LSTM hidden states\n",
    "        num_attention_heads=4,  # Number of attention heads\n",
    "        dropout=0.1,  # Dropout rate\n",
    "        hidden_continuous_size=64,  # Size for processing continuous variables\n",
    "    )\n",
    "\n",
    "    # LSTM model\n",
    "    lstm = LSTM(\n",
    "        **common_params,\n",
    "        loss=MSE(),\n",
    "        hidden_size=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.1,\n",
    "        batch_normalization=True,\n",
    "    )\n",
    "\n",
    "    # RNN model\n",
    "    rnn = RNN(\n",
    "        **common_params,\n",
    "        loss=MAE(),\n",
    "        hidden_size=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.1,\n",
    "        cell_type=\"GRU\",\n",
    "    )\n",
    "\n",
    "    # GRU model\n",
    "    gru = GRU(**common_params, loss=SMAPE(), hidden_size=128, num_layers=2, dropout=0.1)\n",
    "\n",
    "    # Create NeuralForecast object with all models\n",
    "    fcst = NeuralForecast(models=[nbeats, nhits, deepar, tft, lstm, rnn, gru], freq=\"D\")\n",
    "\n",
    "    return fcst\n",
    "\n",
    "\n",
    "def create_darts_models(input_chunk_length=120, output_chunk_length=30, n_epochs=100):\n",
    "    \"\"\"\n",
    "    Create a collection of Darts models with correct parameters\n",
    "    \"\"\"\n",
    "    # Common parameters for neural networks\n",
    "    nn_params = {\n",
    "        \"input_chunk_length\": input_chunk_length,\n",
    "        \"output_chunk_length\": output_chunk_length,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"batch_size\": 32,\n",
    "        \"force_reset\": True,\n",
    "    }\n",
    "\n",
    "    models = {\n",
    "        # Neural network based models\n",
    "        \"nbeats\": NBEATSModel(\n",
    "            **nn_params,\n",
    "            generic_architecture=False,\n",
    "            num_stacks=2,\n",
    "            num_blocks=3,\n",
    "            num_layers=4,\n",
    "            layer_widths=256,\n",
    "            expansion_coefficient_dim=5,\n",
    "            trend_polynomial_degree=2,\n",
    "        ),\n",
    "        \"nhits\": NHiTSModel(\n",
    "            **nn_params,\n",
    "            num_stacks=3,\n",
    "            num_blocks=1,\n",
    "            num_layers=2,\n",
    "            layer_widths=512,\n",
    "            pooling_kernel_sizes=None,\n",
    "            n_freq_downsample=None,\n",
    "            dropout=0.1,\n",
    "            activation=\"ReLU\",\n",
    "            MaxPool1d=True,\n",
    "        ),\n",
    "        \"block_rnn\": BlockRNNModel(\n",
    "            **nn_params,\n",
    "            model=\"LSTM\",\n",
    "            hidden_dim=128,\n",
    "            n_rnn_layers=2,\n",
    "            dropout=0.1,\n",
    "        ),\n",
    "        \"tcn\": TCNModel(\n",
    "            **nn_params,\n",
    "            num_filters=64,\n",
    "            kernel_size=3,\n",
    "            dilation_base=2,\n",
    "            dropout=0.1,\n",
    "            weight_norm=True,\n",
    "        ),\n",
    "        \"tide\": TiDEModel(\n",
    "            **nn_params,\n",
    "            num_encoder_layers=2,\n",
    "            num_decoder_layers=2,\n",
    "            temporal_width_past=24,\n",
    "            temporal_width_future=12,\n",
    "            temporal_decoder_hidden=32,\n",
    "        ),\n",
    "        \"transformer\": TransformerModel(\n",
    "            **nn_params,\n",
    "            d_model=64,\n",
    "            nhead=4,\n",
    "            num_encoder_layers=3,\n",
    "            num_decoder_layers=3,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.1,\n",
    "            activation=\"gelu\",\n",
    "        ),\n",
    "        # Traditional ML models\n",
    "        \"random_forest\": RandomForest(\n",
    "            lags=input_chunk_length,\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "        ),\n",
    "        \n",
    "        \"xgboost\": XGBModel(\n",
    "            lags=input_chunk_length, n_estimators=100, max_depth=6, learning_rate=0.1\n",
    "        ),\n",
    "        \n",
    "    }\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def train_and_forecast(df_train, df_test, use_nixtla=True):\n",
    "    \"\"\"\n",
    "    Train models and generate forecasts using either Nixtla or Darts\n",
    "    \"\"\"\n",
    "    if use_nixtla:\n",
    "        # Nixtla workflow\n",
    "        fcst = create_nixtla_models()\n",
    "\n",
    "        # Ensure df_train has the required columns\n",
    "        if \"unique_id\" not in df_train.columns:\n",
    "            df_train[\"unique_id\"] = \"series0\"\n",
    "        if \"ds\" not in df_train.columns:\n",
    "            df_train = df_train.rename(columns={\"date\": \"ds\"})\n",
    "        if \"y\" not in df_train.columns:\n",
    "            df_train = df_train.rename(columns={\"value\": \"y\"})\n",
    "\n",
    "        # Similarly for test data\n",
    "        if \"unique_id\" not in df_test.columns:\n",
    "            df_test[\"unique_id\"] = \"series0\"\n",
    "        if \"ds\" not in df_test.columns:\n",
    "            df_test = df_test.rename(columns={\"date\": \"ds\"})\n",
    "        if \"y\" not in df_test.columns:\n",
    "            df_test = df_test.rename(columns={\"value\": \"y\"})\n",
    "\n",
    "        fcst.fit(df=df_train, val_size=488)\n",
    "        forecasts = fcst.predict(futr_df=df_test)\n",
    "        return forecasts\n",
    "    else:\n",
    "        # Darts workflow\n",
    "        # Convert pandas DataFrame to Darts TimeSeries\n",
    "        series = TimeSeries.from_dataframe(df_train, \"ds\", \"y\")\n",
    "\n",
    "        # Create and train models\n",
    "        models = create_darts_models()\n",
    "        forecasts = {}\n",
    "\n",
    "        for name, model in models.items():\n",
    "            print(f\"Training {name} model...\")\n",
    "            model.fit(series)\n",
    "            forecast = model.predict(len(df_test))\n",
    "            forecasts[name] = forecast\n",
    "\n",
    "        return forecasts\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# For Nixtla models\n",
    "nixtla_forecasts = train_and_forecast(df_train_commodity_dt, df_test_commodity_dt, use_nixtla=True)\n",
    "\n",
    "# For Darts models\n",
    "darts_forecasts = train_and_forecast(df_train_commodity_dt, df_test_commodity_dt, use_nixtla=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2244.840426</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2261.681818</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2235.193548</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2258.073684</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2291.752941</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>2648.738739</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>2665.293103</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2614.902913</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>2023-05-02</td>\n",
       "      <td>2653.594340</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>2596.029412</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1949 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds            y unique_id\n",
       "0    2018-01-01  2244.840426      Rice\n",
       "1    2018-01-02  2261.681818      Rice\n",
       "2    2018-01-03  2235.193548      Rice\n",
       "3    2018-01-04  2258.073684      Rice\n",
       "4    2018-01-05  2291.752941      Rice\n",
       "...         ...          ...       ...\n",
       "1944 2023-04-29  2648.738739      Rice\n",
       "1945 2023-04-30  2665.293103      Rice\n",
       "1946 2023-05-01  2614.902913      Rice\n",
       "1947 2023-05-02  2653.594340      Rice\n",
       "1948 2023-05-03  2596.029412      Rice\n",
       "\n",
       "[1949 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = df_train_commodity_dt['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 511 K  | train\n",
      "-------------------------------------------------------------\n",
      "465 K     Trainable params\n",
      "46.2 K    Non-trainable params\n",
      "511 K     Total params\n",
      "2.048     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training nbeats model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022789eb78fe4755b050d94eea99d20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ed0d10daec4076a0233e0a547322f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 968 K  | train\n",
      "-------------------------------------------------------------\n",
      "907 K     Trainable params\n",
      "61.6 K    Non-trainable params\n",
      "968 K     Total params\n",
      "3.876     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training nhits model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4519b520e2f41318164aef4cb43a268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e48dc72f7974c829e1961cfe37e8f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 199 K  | train\n",
      "6 | fc              | Sequential       | 3.9 K  | train\n",
      "-------------------------------------------------------------\n",
      "203 K     Trainable params\n",
      "0         Non-trainable params\n",
      "203 K     Total params\n",
      "0.812     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training block_rnn model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1e285b10014aecab9dc740c5ec59be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef753c876050430fadcdc17bbea1a9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shri/learning/sih/krushiJyothishii/sih_2024/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | res_blocks      | ModuleList       | 100 K  | train\n",
      "-------------------------------------------------------------\n",
      "100 K     Trainable params\n",
      "0         Non-trainable params\n",
      "100 K     Total params\n",
      "0.400     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tcn model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1c6057035e450a82b0e9778260944d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e6276f10ef47e0b7326de4f0785c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 97.0 K | train\n",
      "6 | decoders         | Sequential       | 189 K  | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 3.6 K  | train\n",
      "--------------------------------------------------------------\n",
      "291 K     Trainable params\n",
      "0         Non-trainable params\n",
      "291 K     Total params\n",
      "1.165     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tide model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b4028d82b84fa282353dc22eaa08f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbdc1620d364a758416a1df61cd4143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shri/learning/sih/krushiJyothishii/sih_2024/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 128    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 350 K  | train\n",
      "8 | decoder             | Linear              | 1.9 K  | train\n",
      "--------------------------------------------------------------------\n",
      "352 K     Trainable params\n",
      "0         Non-trainable params\n",
      "352 K     Total params\n",
      "1.410     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transformer model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836b7db4cccb4393a53c0f67f023fd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d704ceddd94c4a60b8e27bf42bed0cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random_forest model...\n",
      "Training xgboost model...\n"
     ]
    }
   ],
   "source": [
    "nixtla_forecasts = train_and_forecast(\n",
    "    df_train_commodity_dt, df_test_commodity_dt, use_nixtla=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nbeats': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[2639.33696788]],\n",
       " \n",
       "        [[2615.77879673]],\n",
       " \n",
       "        [[2625.00163047]],\n",
       " \n",
       "        [[2640.62315947]],\n",
       " \n",
       "        [[2627.40220068]],\n",
       " \n",
       "        [[2595.34941697]],\n",
       " \n",
       "        [[2601.16252655]],\n",
       " \n",
       "        [[2638.49261573]],\n",
       " \n",
       "        [[2608.34834722]],\n",
       " \n",
       "        [[2618.15027147]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2596.88305078]],\n",
       " \n",
       "        [[2591.0446558 ]],\n",
       " \n",
       "        [[2582.96959298]],\n",
       " \n",
       "        [[2584.52410646]],\n",
       " \n",
       "        [[2591.94867862]],\n",
       " \n",
       "        [[2587.26991158]],\n",
       " \n",
       "        [[2590.07644368]],\n",
       " \n",
       "        [[2600.14847853]],\n",
       " \n",
       "        [[2589.23266195]],\n",
       " \n",
       "        [[2588.09429026]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'nhits': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[2653.23030267]],\n",
       " \n",
       "        [[2638.9559018 ]],\n",
       " \n",
       "        [[2643.8689734 ]],\n",
       " \n",
       "        [[2654.3090718 ]],\n",
       " \n",
       "        [[2658.81957271]],\n",
       " \n",
       "        [[2621.15206782]],\n",
       " \n",
       "        [[2628.74332023]],\n",
       " \n",
       "        [[2654.1470893 ]],\n",
       " \n",
       "        [[2622.88142625]],\n",
       " \n",
       "        [[2634.92935712]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2940.27183633]],\n",
       " \n",
       "        [[2936.16144448]],\n",
       " \n",
       "        [[2938.37193894]],\n",
       " \n",
       "        [[2935.71312125]],\n",
       " \n",
       "        [[2942.0506727 ]],\n",
       " \n",
       "        [[2946.07873614]],\n",
       " \n",
       "        [[2941.19300135]],\n",
       " \n",
       "        [[2944.85779788]],\n",
       " \n",
       "        [[2938.13233126]],\n",
       " \n",
       "        [[2943.90386874]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'block_rnn': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[710.13835729]],\n",
       " \n",
       "        [[710.23995476]],\n",
       " \n",
       "        [[709.42207898]],\n",
       " \n",
       "        [[708.97893489]],\n",
       " \n",
       "        [[709.94975191]],\n",
       " \n",
       "        [[710.06603933]],\n",
       " \n",
       "        [[710.34308446]],\n",
       " \n",
       "        [[709.14601551]],\n",
       " \n",
       "        [[709.32459236]],\n",
       " \n",
       "        [[709.5201237 ]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[709.37735159]],\n",
       " \n",
       "        [[709.8720333 ]],\n",
       " \n",
       "        [[709.70532792]],\n",
       " \n",
       "        [[709.04110672]],\n",
       " \n",
       "        [[710.81281104]],\n",
       " \n",
       "        [[709.61738432]],\n",
       " \n",
       "        [[710.09241593]],\n",
       " \n",
       "        [[711.38863835]],\n",
       " \n",
       "        [[710.52272742]],\n",
       " \n",
       "        [[710.73230809]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'tcn': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[2580.51868742]],\n",
       " \n",
       "        [[2568.7825192 ]],\n",
       " \n",
       "        [[2573.64823631]],\n",
       " \n",
       "        [[2560.79742507]],\n",
       " \n",
       "        [[2572.39010728]],\n",
       " \n",
       "        [[2566.21075891]],\n",
       " \n",
       "        [[2573.45900533]],\n",
       " \n",
       "        [[2578.80046028]],\n",
       " \n",
       "        [[2579.45971689]],\n",
       " \n",
       "        [[2565.19877843]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2522.46228886]],\n",
       " \n",
       "        [[2522.68562595]],\n",
       " \n",
       "        [[2522.56416252]],\n",
       " \n",
       "        [[2521.87794481]],\n",
       " \n",
       "        [[2521.80853544]],\n",
       " \n",
       "        [[2522.22811251]],\n",
       " \n",
       "        [[2522.13584661]],\n",
       " \n",
       "        [[2522.22449107]],\n",
       " \n",
       "        [[2523.11516008]],\n",
       " \n",
       "        [[2523.62440634]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'tide': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[2604.95396584]],\n",
       " \n",
       "        [[2579.40368664]],\n",
       " \n",
       "        [[2588.59134759]],\n",
       " \n",
       "        [[2571.54597844]],\n",
       " \n",
       "        [[2581.61982005]],\n",
       " \n",
       "        [[2608.12544832]],\n",
       " \n",
       "        [[2540.99454722]],\n",
       " \n",
       "        [[2611.05104685]],\n",
       " \n",
       "        [[2566.90282285]],\n",
       " \n",
       "        [[2574.04424968]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2138.33678531]],\n",
       " \n",
       "        [[2196.2207115 ]],\n",
       " \n",
       "        [[2154.2656631 ]],\n",
       " \n",
       "        [[2173.16565988]],\n",
       " \n",
       "        [[2126.81251633]],\n",
       " \n",
       "        [[2154.21317124]],\n",
       " \n",
       "        [[2184.34391765]],\n",
       " \n",
       "        [[2159.35690176]],\n",
       " \n",
       "        [[2177.695241  ]],\n",
       " \n",
       "        [[2161.062243  ]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'transformer': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[2486.50220194]],\n",
       " \n",
       "        [[2485.81931822]],\n",
       " \n",
       "        [[2486.37193415]],\n",
       " \n",
       "        [[2487.01801858]],\n",
       " \n",
       "        [[2486.84297076]],\n",
       " \n",
       "        [[2486.74749753]],\n",
       " \n",
       "        [[2487.27810682]],\n",
       " \n",
       "        [[2487.56748436]],\n",
       " \n",
       "        [[2487.62205975]],\n",
       " \n",
       "        [[2487.37326102]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2489.35459499]],\n",
       " \n",
       "        [[2488.98180054]],\n",
       " \n",
       "        [[2490.02916831]],\n",
       " \n",
       "        [[2489.9143292 ]],\n",
       " \n",
       "        [[2490.00096708]],\n",
       " \n",
       "        [[2489.88441298]],\n",
       " \n",
       "        [[2490.60072595]],\n",
       " \n",
       "        [[2489.89102811]],\n",
       " \n",
       "        [[2490.89236677]],\n",
       " \n",
       "        [[2490.89382433]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'random_forest': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 4kB\n",
       " array([[[2630.14696835]],\n",
       " \n",
       "        [[2626.5746029 ]],\n",
       " \n",
       "        [[2620.82806745]],\n",
       " \n",
       "        [[2637.4294185 ]],\n",
       " \n",
       "        [[2628.34093289]],\n",
       " \n",
       "        [[2618.10445625]],\n",
       " \n",
       "        [[2615.81183616]],\n",
       " \n",
       "        [[2632.68166714]],\n",
       " \n",
       "        [[2619.34745815]],\n",
       " \n",
       "        [[2624.96966107]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2612.98216591]],\n",
       " \n",
       "        [[2612.82667956]],\n",
       " \n",
       "        [[2613.19328895]],\n",
       " \n",
       "        [[2613.41089691]],\n",
       " \n",
       "        [[2612.67270489]],\n",
       " \n",
       "        [[2613.65921048]],\n",
       " \n",
       "        [[2613.79607851]],\n",
       " \n",
       "        [[2613.43418593]],\n",
       " \n",
       "        [[2613.58105362]],\n",
       " \n",
       "        [[2613.2851538 ]]])\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None,\n",
       " 'xgboost': <TimeSeries (DataArray) (ds: 488, component: 1, sample: 1)> Size: 2kB\n",
       " array([[[2643.025 ]],\n",
       " \n",
       "        [[2628.4717]],\n",
       " \n",
       "        [[2614.6094]],\n",
       " \n",
       "        [[2645.8276]],\n",
       " \n",
       "        [[2636.5244]],\n",
       " \n",
       "        [[2633.146 ]],\n",
       " \n",
       "        [[2612.111 ]],\n",
       " \n",
       "        [[2673.8618]],\n",
       " \n",
       "        [[2619.1516]],\n",
       " \n",
       "        [[2635.858 ]],\n",
       " \n",
       " ...\n",
       " \n",
       "        [[2608.4238]],\n",
       " \n",
       "        [[2634.5613]],\n",
       " \n",
       "        [[2626.5298]],\n",
       " \n",
       "        [[2614.1062]],\n",
       " \n",
       "        [[2603.6758]],\n",
       " \n",
       "        [[2606.0178]],\n",
       " \n",
       "        [[2607.1157]],\n",
       " \n",
       "        [[2613.419 ]],\n",
       " \n",
       "        [[2622.374 ]],\n",
       " \n",
       "        [[2621.4473]]], dtype=float32)\n",
       " Coordinates:\n",
       "   * ds         (ds) datetime64[ns] 4kB 2023-05-04 2023-05-05 ... 2024-09-02\n",
       "   * component  (component) object 8B 'y'\n",
       " Dimensions without coordinates: sample\n",
       " Attributes:\n",
       "     static_covariates:  None\n",
       "     hierarchy:          None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nixtla_forecasts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
